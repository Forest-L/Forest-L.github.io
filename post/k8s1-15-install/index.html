<!DOCTYPE html>
<html lang="zh">

<head>
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	
	<title>李林博客  | k8s1.15安装</title>
	<meta name="viewport" content="width=device-width,minimum-scale=1">
	<meta name="generator" content="Hugo 0.74.3" />
	
	
	<META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">
	

	
	
	<link href="/dist/app.css" rel="stylesheet">
	

	

	
	
<link rel="shortcut icon" href="img/K8s.png" type="image/png" />

	

	
	
	
	
	
	



<link rel="stylesheet" href='https://kubesphereio.com/lib/katex.min.css' integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">


<script defer src='https://kubesphereio.com/lib/katex.min.js' integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>


<script defer src='https://kubesphereio.com/lib/contrib/auto-render.min.js' integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI"
crossorigin="anonymous"
onload='renderMathInElement(document.body);'></script>


<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
</script>

	
	
	
	<script>
		(function (u, c) {
			var d = document,
				t = 'script',
				o = d.createElement(t),
				s = d.getElementsByTagName(t)[0];
			o.src = u;
			if (c) {
				o.addEventListener('load', function (e) {
					c(e);
				});
			}
			s.parentNode.insertBefore(o, s);
		})('https:\/\/kubesphereio.com\/lib\/pangu.min.js', function () {
			pangu.spacingPage();
		});
	</script>
	
	
	<style type="text/css" media="screen, print">
		@font-face {
			font-family: "FancyTitleFont";
			font-style: normal;
			font-display: swap;
			src: url('https://kubesphereio.com/fonts/exampleFont.woff2') format('woff2'),
				url('https://kubesphereio.com/fonts/exampleFont.woff') format('woff');
		}

		 
		@font-face {
			font-family: 'Noto Serif CJK SC';
			font-style: normal;
			font-weight: 300;
			font-display: swap;
			src: local('Noto Serif CJK SC Light'), local('NotoSerifCJK-Light'),
				url('https://kubesphereio.com/fonts/noto-serif-sc-v7-latin_chinese-simplified-300.woff2') format('woff2'),
				 
				url('https://kubesphereio.com/fonts/noto-serif-sc-v7-latin_chinese-simplified-300.woff') format('woff');
			 
		}

		 
		@font-face {
			font-family: 'Noto Serif CJK SC';
			font-style: normal;
			font-weight: 400;
			font-display: swap;
			src: local('Noto Serif CJK SC'), local('NotoSerifCJK-Regular'),
				url('https://kubesphereio.com/fonts/noto-serif-sc-v7-latin_chinese-simplified-regular.woff2') format('woff2'),
				 
				url('https://kubesphereio.com/fonts/noto-serif-sc-v7-latin_chinese-simplified-regular.woff') format('woff');
			 
		}

		 
		@font-face {
			font-family: 'Noto Serif CJK SC';
			font-style: normal;
			font-weight: 500;
			font-display: swap;
			src: local('Noto Serif CJK SC Medium'), local('NotoSerifCJK-Medium'),
				url('https://kubesphereio.com/fonts/noto-serif-sc-v7-latin_chinese-simplified-500.woff2') format('woff2'),
				 
				url('https://kubesphereio.com/fonts/noto-serif-sc-v7-latin_chinese-simplified-500.woff') format('woff');
			 
		}
	</style>
	
	
</head>

<body class="bg-gray-100 text-gray-700 font-sans">
	<div class="p-6 sm:p-10 md:p-16 flex flex-wrap">
		<header class="w-full md:w-2/5 xl:w-1/2 md:pr-12 lg:pr-20 xl:pr-24 order-1 md:order-1 max-w-2xl">
			<div
				class="z-50 bg-gray-100 bg-opacity-75 bg-opacity-custom lg:min-w-0.7 max-w-xl md:float-right md:text-right leading-loose tracking-tight md:sticky md:top-0 pt-2">
				
<div>
	<h2>
		<a href="https://kubesphereio.com/" title="李林博客" class="heading font-cursive icon">李林博客</a>
	</h2>
</div>
<h1 class="pt-2">k8s1.15安装</h1>

<div class="flex flex-wrap justify-end pt-2 "><div class="md:flex-grow-0 font-light">
	

	

	
	
	
	
	<a class="post-taxonomy-tag text-eucalyptus-500"
		href='/tags/k8s'>K8s</a>
	
	
	
</div><time class="text-eucalyptus-500 md:text-right md:flex-grow font-light pl-4"
		datetime="2019-11-04T00:00:00Z">2019-11-4 00:00</time>
</div>

<hr />

			</div>
		</header>
		<main role="main" class="w-full md:w-3/5 xl:w-1/2 max-w-3xl order-2 md:order-2 min-h-70vh pt-2 pb-4">
			

<article>
	<section class="mx-auto content">
		<div class="c-rich-text"><h1 id="使用kubeadm安装k8s-115版本">使用kubeadm安装k8s 1.15版本</h1>
<p>k8s 1.15版本中，kubeadm对HA集群的配置已经达到了beta可用，这一版本更新主要是针对稳定性的持续改善和可扩展性。其中用到的镜像和rpm包在百度云上，链接如下。
<a href="https://pan.baidu.com/s/1LoKvv86Fs5ilZ-TYQdN35A">https://pan.baidu.com/s/1LoKvv86Fs5ilZ-TYQdN35A</a>
cos3</p>
<h2 id="1准备">1.准备</h2>
<h3 id="11系统准备">1.1系统准备</h3>
<p>需要将主机ip和主机名放在每台机器的<code>vi /etc/hosts</code>下
<code>192.168.11.21 i-fahx5c7k</code>
<code>192.168.11.22 i-ouaaujhz</code>
如果各个主机启用了防火墙，需要开启各个组件所需要的端口，可以查看https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/
这里各个节点禁用防火墙
<code>systemctl stop firewalld</code>
<code>systemctl disable firewalld</code>
禁用selinux
<code>setenforce 0</code>
vi /etc/selinux/config
SELINUX=disabled
创建vi /etc/sysctl.d/k8s.conf文件，添加如下内容：
<code>net.bridge.bridge-nf-call-ip6tables = 1</code>
<code>net.bridge.bridge-nf-call-iptables = 1</code>
<code>net.ipv4.ip_forward = 1</code>
执行命令使修改生效
<code>modprobe br_netfilter</code>
<code>sysctl -p /etc/sysctl.d/k8s.conf</code></p>
<h3 id="12-kube-proxy开启ipvs的前置条件">1.2 kube-proxy开启ipvs的前置条件</h3>
<p>在所有的节点上执行如下脚本：</p>
<pre><code>cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF
chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -e nf_conntrack_ipv4

各个节点需要安装 ipset ipvsadm
yum install ipset ipvsadm -y
</code></pre><h3 id="13-docker安装">1.3 docker安装</h3>
<p>安装docker的yum源,国内寻找清华源
<code>yum install wget -y</code>
<code>yum install -y yum-utils device-mapper-persistent-data lvm2</code>
<code>wget -O /etc/yum.repos.d/docker-ce.repo https://download.docker.com/linux/centos/docker-ce.repo</code>
<code>sed -i 's+download.docker.com+mirrors.tuna.tsinghua.edu.cn/docker-ce+' /etc/yum.repos.d/docker-ce.repo</code>
<code>yum makecache fast</code>
<code>yum install docker-ce -y</code>
重启docker：<code>systemctl enable docker;systemctl restart docker</code>
修改docker cgroup driver为systemd
创建或修改<code>vi /etc/docker/daemon.json</code>：</p>
<pre><code>{
  &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]
}
</code></pre><p>重启docker:<code>systemctl restart docker</code></p>
<h2 id="2-使用kubeadm部署kubernetes">2. 使用kubeadm部署kubernetes</h2>
<h3 id="21-安装kubeadm和kubelet">2.1 安装kubeadm和kubelet</h3>
<p>下面在各节点安装kubeadm和kubelet和kubectl，请在百度云上面下载rpm包，在rmp目录下执行如下指令：
<code>yum install -y cri-tools-1.13.0-0.x86_64.rpm kubernetes-cni-0.7.5-0.x86_64.rpm kubelet-1.15.1-0.x86_64.rpm kubectl-1.15.1-0.x86_64.rpm kubeadm-1.15.1-0.x86_64.rpm </code>
k8s 1.8开始要求关闭系统的swap,不关闭，kubelet将无法启动，执行指令方法：
<code>swapoff -a</code>
修改 /etc/fstab 文件，注释掉 SWAP 的自动挂载，使用free -m确认swap已经关闭。 swappiness参数调整，修改<code>vi /etc/sysctl.d/k8s.conf</code>添加下面一行：
<code>vm.swappiness=0</code>
执行<code>sysctl -p /etc/sysctl.d/k8s.conf</code>使修改生效。
因为这里本次测试主机上还运行其他服务，关闭swap可能会对其他服务产生影响，所以这里修改kubelet的配置去掉这个限制。
修改<code>vi /etc/sysconfig/kubelet</code>，加入：<code>KUBELET_EXTRA_ARGS=--fail-swap-on=false</code></p>
<h3 id="22-使用kubeadm-init初始化集群">2.2 使用kubeadm init初始化集群</h3>
<p>在各节点开机启动kubelet服务：<code>systemctl enable kubelet</code>
使用<code>kubeadm config print init-defaults</code>可以打印集群初始化默认的使用的配置:</p>
<pre><code>apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 1.2.3.4
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  name: node1
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: k8s.gcr.io
kind: ClusterConfiguration
kubernetesVersion: v1.14.0
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
scheduler: {}
</code></pre><p>从默认的配置中可以看到，可以使用imageRepository定制在集群初始化时拉取k8s所需镜像的地址。advertiseAddress的ip替换本机，基于默认配置定制出本次使用kubeadm初始化集群所需的配置文件且在11.21机器上<code>vi kubeadm.yaml</code>：</p>
<pre><code>apiVersion: kubeadm.k8s.io/v1beta2
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.11.21
  bindPort: 6443
nodeRegistration:
  taints:
  - effect: PreferNoSchedule
    key: node-role.kubernetes.io/master
---
apiVersion: kubeadm.k8s.io/v1beta2
kind: ClusterConfiguration
kubernetesVersion: v1.15.0
networking:
  podSubnet: 10.244.0.0/16
</code></pre><p><font color=#DC143C >说 明 : </font>
使用kubeadm默认配置初始化的集群，会在master节点打上node-role.kubernetes.io/master:NoSchedule的污点，阻止master节点接受调度运行工作负载。这里测试环境只有两个节点，所以将这个taint修改为node-role.kubernetes.io/master:PreferNoSchedule。</p>
<p>在开始初始化集群之前，需要从百度云上面下载tar包镜像下来，tar通过scp分别传到各个节点执行docker load -i解压，
镜像列表:</p>
<pre><code>k8s.gcr.io/kube-proxy                v1.15.0             d235b23c3570        5 weeks ago         82.4MB
k8s.gcr.io/kube-apiserver            v1.15.0             201c7a840312        5 weeks ago         207MB
k8s.gcr.io/kube-scheduler            v1.15.0             2d3813851e87        5 weeks ago         81.1MB
k8s.gcr.io/kube-controller-manager   v1.15.0             8328bb49b652        5 weeks ago         159MB
gcr.io/kubernetes-helm/tiller        v2.14.1             ac22eb1f780e        7 weeks ago         94.2MB
quay.io/coreos/flannel               v0.11.0-amd64       ff281650a721        6 months ago        52.6MB
k8s.gcr.io/coredns                   1.3.1               eb516548c180        6 months ago        40.3MB
k8s.gcr.io/etcd                      3.3.10              2c4adeb21b4f        8 months ago        258MB
k8s.gcr.io/pause                     3.1                 da86e6ba6ca1        19 months ago       742kB
</code></pre><p>接下来使用kubeadm初始化集群，选择node1作为Master Node，在node1上执行下面的命令：<code>kubeadm init --config kubeadm.yaml --ignore-preflight-errors=Swap</code></p>
<p><code>kubeadm join 192.168.11.21:6443 --token k6s0kn.nyao1ulwwmlm2org \ --discovery-token-ca-cert-hash sha256:b721d25356668f921c90bf5f554836cb346b827a62b78797d0bcbcba24214725 </code></p>
<pre><code>其中关键步骤：
* [kubelet-start] 生成kubelet的配置文件”/var/lib/kubelet/config.yaml”
* [certs]生成相关的各种证书
* [kubeconfig]生成相关的kubeconfig文件
* [control-plane]使用/etc/kubernetes/manifests目录中的yaml文件创建apiserver、controller-manager、scheduler的静态pod
* [bootstraptoken]生成token记录下来，后边使用kubeadm join往集群中添加节点时会用到
* 下面的命令是配置常规用户如何使用kubectl访问集群：
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
* 最后给出了将节点加入集群的命令kubeadm join 192.168.99.11:6443 –token 4qcl2f.gtl3h8e5kjltuo0r \ –discovery-token-ca-cert-hash sha256:7ed5404175cc0bf18dbfe53f19d4a35b1e3d40c19b10924275868ebf2a3bbe6e
</code></pre><p>需要在11.21机器上执行：
<code>mkdir -p $HOME/.kube</code>
<code>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</code>
<code>sudo chown $(id -u):$(id -g) $HOME/.kube/config</code>
查看集群状态，确认组件都处于healthy状态：
<code>kubectl get cs</code>
集群初始化如果遇到问题，可以使用下面的命令进行清理：
<code>kubeadm reset</code></p>
<h3 id="23-安装pod-network">2.3 安装Pod Network</h3>
<p>接下来安装flannel network add-on：
<code>mkdir -p ~/k8s/</code>
<code>cd ~/k8s</code>
<code>curl -O https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</code>
<code>kubectl apply -f  kube-flannel.yml</code>
这里注意kube-flannel.yml这个文件里的flannel的镜像是0.11.0，quay.io/coreos/flannel:v0.11.0-amd64
如果Node有多个网卡的话，参考https://github.com/kubernetes/kubernetes/issues/39701，
目前需要在kube-flannel.yml中使用–iface参数指定集群主机内网网卡的名称，否则可能会出现dns无法解析。需要将kube-flannel.yml下载到本地，flanneld启动参数加上–iface=<iface-name></p>
<pre><code>containers:
      - name: kube-flannel
        image: quay.io/coreos/flannel:v0.11.0-amd64
        command:
        - /opt/bin/flanneld
        args:
        - --ip-masq
        - --kube-subnet-mgr
        - --iface=eth1
......
</code></pre><p>使用<code>kubectl get pod –-all-namespaces -o wide</code>确保所有的Pod都处于Running状态。</p>
<pre><code>kube-flannel.yml
[root@i-fahx5c7k k8s]# kubectl get pod --all-namespaces -o wide
NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES
kube-system   coredns-5c98db65d4-nbb4w             1/1     Running   0          6m29s   10.244.0.2      i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-5c98db65d4-wtm58             1/1     Running   0          6m29s   10.244.0.3      i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-i-fahx5c7k                      1/1     Running   0          5m26s   192.168.11.21   i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-i-fahx5c7k            1/1     Running   0          5m37s   192.168.11.21   i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-i-fahx5c7k   1/1     Running   0          5m45s   192.168.11.21   i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
kube-system   kube-flannel-ds-amd64-bqswg          1/1     Running   0          58s     192.168.11.21   i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-zhzxj                     1/1     Running   0          6m29s   192.168.11.21   i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-i-fahx5c7k            1/1     Running   0          5m20s   192.168.11.21   i-fahx5c7k   &lt;none&gt;           &lt;none&gt;
</code></pre><h3 id="24-测试集群dns是否可用">2.4 测试集群DNS是否可用</h3>
<p><code>kubectl run curl --image=radial/busyboxplus:curl -it</code>
进入后执行<code>nslookup kubernetes.default</code>确认解析正常:</p>
<pre><code>[ root@curl-6bf6db5c4f-f8jjn:/ ]$ nslookup kubernetes.default
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default
Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local
</code></pre><h3 id="25-向kubernetes集群中添加node节点">2.5 向Kubernetes集群中添加Node节点</h3>
<p>在master上查看添加节点指令：<code>kubeadm token create --print-join-command</code>
下面将11.22这个主机添加到Kubernetes集群中，在11.22机器上执行:
<code>kubeadm join 192.168.11.21:6443 --token k6s0kn.nyao1ulwwmlm2org \ --discovery-token-ca-cert-hash sha256:b721d25356668f921c90bf5f554836cb346b827a62b78797d0bcbcba24214725</code>
11.22加入集群很是顺利，下面在master节点上执行命令查看集群中的节点：</p>
<pre><code>[root@i-fahx5c7k k8s]# kubectl get nodes
NAME         STATUS   ROLES    AGE   VERSION
i-fahx5c7k   Ready    master   13m   v1.15.1
i-ouaaujhz   Ready    &lt;none&gt;   50s   v1.15.1
</code></pre><h4 id="251-如何从集群中移除node">2.5.1 如何从集群中移除Node</h4>
<p>如果需要从集群中移除11.22这个Node执行下面的命令：
在master节点上执行：
<code>kubectl drain i-ouaaujhz --delete-local-data --force --ignore-daemonsets</code></p>
<p><code>kubectl delete node i-ouaaujhz</code>
在11.22上执行：
<code>kubeadm reset</code></p>
<h3 id="kube-proxy开启ipvs">kube-proxy开启ipvs</h3>
<p>修改ConfigMap的kube-system/kube-proxy中的config.conf，mode: “ipvs”
<code>kubectl edit cm kube-proxy -n kube-system</code>
之后重启各个节点上的kube-proxy pod：
<code>kubectl get pod -n kube-system | grep kube-proxy | awk '{system(&quot;kubectl delete pod &quot;$1&quot; -n kube-system&quot;)}'</code>
日志查看：<code>kubectl logs kube-proxy-62ntf  -n kube-system</code>出现ipvs即开启。</p>
<h2 id="3kubernetes常用组件部署">3.Kubernetes常用组件部署</h2>
<p>使用Helm这个Kubernetes的包管理器，这里也将使用Helm安装Kubernetes的常用组件。</p>
<h3 id="31-helm的安装">3.1 Helm的安装</h3>
<p>Helm由客户端命helm令行工具和服务端tiller组成，Helm的安装十分简单。 下载helm命令行工具到master节点node1的/usr/local/bin下，这里下载的2.14.1版本：</p>
<p><code>curl -O https://get.helm.sh/helm-v2.14.1-linux-amd64.tar.gz</code>
<code>tar -zxvf helm-v2.14.1-linux-amd64.tar.gz</code>
<code>cd linux-amd64/</code>
<code>cp helm /usr/local/bin/</code>
为了安装服务端tiller，还需要在这台机器上配置好kubectl工具和kubeconfig文件，确保kubectl工具可以在这台机器上访问apiserver且正常使用。 这里的11.21节点已经配置好了kubectl。
因为Kubernetes APIServer开启了RBAC访问控制，所以需要创建tiller使用的service account: tiller并分配合适的角色给它。这里简单起见直接分配cluster-admin这个集群内置的ClusterRole给它。创建<code>vi helm-rbac.yaml</code>文件：</p>
<pre><code>apiVersion: v1
kind: ServiceAccount
metadata:
  name: tiller
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: tiller
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: tiller
    namespace: kube-system
</code></pre><p><code>kubectl create -f helm-rbac.yaml</code>
接下来使用helm部署tiller:
<code>helm init --service-account tiller --skip-refresh</code>
tiller默认被部署在k8s集群中的kube-system这个namespace下：</p>
<pre><code>[root@i-fahx5c7k centosrepo]# kubectl get pod -n kube-system -l app=helm
NAME                             READY   STATUS    RESTARTS   AGE
tiller-deploy-7bf78cdbf7-46bv5   1/1     Running   0          22s
</code></pre><p><code>helm version</code></p></div>
	</section>


</article>

		</main>
		<aside role="contentinfo"
			class="w-full md:w-2/5 xl:w-1/2 md:pr-12 lg:pr-20 xl:pr-24 order-4 md:order-3 md:sticky md:bottom-0 self-end max-w-2xl">
			<div class="md:float-right md:text-right leading-loose tracking-tight md:mb-2">
				
	<div class="md:max-w-xs  flex flex-col md:items-end">
	<ul class="font-serif flex-grow-0 flex justify-between flex-wrap md:flex-col">
	
	
	<li class="px-1 md:px-0">
		<a href="/tags/" title="标签 page" >
			标签
		</a>
	</li>
	
	<li class="px-1 md:px-0">
		<a href="/categories/" title="分类 page" >
			分类
		</a>
	</li>
	
	<li class="px-1 md:px-0">
		<a href="/about/" title="关于 page" >
			关于
		</a>
	</li>
	
	
	
	
	<div id="fastSearch" class="m-0">
		<input id="searchInput" type="text" size=10 
			class="bg-gray-100 focus:outline-none border-b border-gray-100 focus:border-eucalyptus-300 md:text-right
			placeholder-java-500 min-w-0 max-w-xxxs"
			placeholder="搜索" />
		<ul id="searchResults" class="bg-gray-200 px-2 divide-y divide-gray-400">
		</ul>
	</div>
	
</ul>
	

<div class="flex flex-wrap-reverse md:justify-end content-end md:content-start justify-start items-start   max-h-16">
	
	<a href='https://github.com/Forest-L/Forest-L.github.io' target="_blank" class="github icon pl-1 text-eucalyptus-400 hover:text-java-400" title="github link" rel="noopener"
		aria-label="follow on github——Opens in a new window">
		
		<div class="fill-current h-8 w-8">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <g>
        <path fill="none" d="M0 0h24v24H0z"/>
        <path fill-rule="nonzero" d="M5.883 18.653c-.3-.2-.558-.455-.86-.816a50.32 50.32 0 0 1-.466-.579c-.463-.575-.755-.84-1.057-.949a1 1 0 0 1 .676-1.883c.752.27 1.261.735 1.947 1.588-.094-.117.34.427.433.539.19.227.33.365.44.438.204.137.587.196 1.15.14.023-.382.094-.753.202-1.095C5.38 15.31 3.7 13.396 3.7 9.64c0-1.24.37-2.356 1.058-3.292-.218-.894-.185-1.975.302-3.192a1 1 0 0 1 .63-.582c.081-.024.127-.035.208-.047.803-.123 1.937.17 3.415 1.096A11.731 11.731 0 0 1 12 3.315c.912 0 1.818.104 2.684.308 1.477-.933 2.613-1.226 3.422-1.096.085.013.157.03.218.05a1 1 0 0 1 .616.58c.487 1.216.52 2.297.302 3.19.691.936 1.058 2.045 1.058 3.293 0 3.757-1.674 5.665-4.642 6.392.125.415.19.879.19 1.38a300.492 300.492 0 0 1-.012 2.716 1 1 0 0 1-.019 1.958c-1.139.228-1.983-.532-1.983-1.525l.002-.446.005-.705c.005-.708.007-1.338.007-1.998 0-.697-.183-1.152-.425-1.36-.661-.57-.326-1.655.54-1.752 2.967-.333 4.337-1.482 4.337-4.66 0-.955-.312-1.744-.913-2.404a1 1 0 0 1-.19-1.045c.166-.414.237-.957.096-1.614l-.01.003c-.491.139-1.11.44-1.858.949a1 1 0 0 1-.833.135A9.626 9.626 0 0 0 12 5.315c-.89 0-1.772.119-2.592.35a1 1 0 0 1-.83-.134c-.752-.507-1.374-.807-1.868-.947-.144.653-.073 1.194.092 1.607a1 1 0 0 1-.189 1.045C6.016 7.89 5.7 8.694 5.7 9.64c0 3.172 1.371 4.328 4.322 4.66.865.097 1.201 1.177.544 1.748-.192.168-.429.732-.429 1.364v3.15c0 .986-.835 1.725-1.96 1.528a1 1 0 0 1-.04-1.962v-.99c-.91.061-1.662-.088-2.254-.485z"/>
    </g>
</svg>

		</div>
	</a>
	
	<a href='lilin13297@gmail.com' target="_blank" class="mail icon pl-1 text-eucalyptus-400 hover:text-java-400" title="mail link" rel="noopener"
		aria-label="follow on mail——Opens in a new window">
		
		<div class="fill-current h-8 w-8">
			<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <g>
        <path fill="none" d="M0 0h24v24H0z"/>
        <path d="M3 3h18a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1zm17 4.238l-7.928 7.1L4 7.216V19h16V7.238zM4.511 5l7.55 6.662L19.502 5H4.511z"/>
    </g>
</svg>
		</div>
	</a>
	
</div>
	<div class="text-sm text-gray-500 leading-tight a-gray">
		Copyright © 2008–2020
		<br />
		Built with Hugo and theme <a href="https://github.com/heyeshuang/hugo-theme-tokiwa">Tokiwa</a>. 3627 words in this page.
	</div>
</div>

			</div>
		</aside>
		<footer class="w-full md:w-3/5 xl:w-1/2 order-3 max-w-3xl md:order-4 pt-2">
			
<hr class="double-line" />
<div class="flex flex-wrap justify-between pb-2 leading-loose font-serif">
    
    <a class="flex-grow-0" href="/post/docker-image-operation-guide-for-building-arm-x86-architecture/">
        <svg class="fill-current inline-block h-4 w-4" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24"
            height="24">
            <path fill="none" d="M0 0h24v24H0z" />
            <path d="M7.828 11H20v2H7.828l5.364 5.364-1.414 1.414L4 12l7.778-7.778 1.414 1.414z" /></svg>
        构建arm-x86架构的docker-image操作指南
    </a>
    
    
    <a class="flex-grow-0" href="/post/kubesphere-does-cluster-migration-based-on-velero/">
        Kubesphere基于Velero做集群的迁移
        <svg class="fill-current inline-block h-4 w-4" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24"
            height="24">
            <path fill="none" d="M0 0h24v24H0z" />
            <path d="M16.172 11l-5.364-5.364 1.414-1.414L20 12l-7.778 7.778-1.414-1.414L16.172 13H4v-2z" /></svg></a>
    
</div>
<div >



<div class="font-serif pb-2 flex align-start leading-loose">
	<span class="heading pr-6 leading-loose">Related</span>
	<span >
		
			<a href="/post/k8s1.16-installed-on-centos-system/">K8s1.16在centos安装</a>&nbsp;&nbsp;&#47;&nbsp;
		
			<a href="/post/add-public-ip-to-kubernetes-apiserver-operation-guide/">添加公网ip到kubernetes的apiserver操作指南</a>
		
</span>
</div>

</div>
<hr />
<div class="pb-2">
    
</div>
<hr />

		</footer>
		

<script src="/dist/app.js"></script>


<script src="/lib/fuse.min.js"></script> 
<script src="/lib/fastsearch.js"></script>

	</div>
</body>

</html>